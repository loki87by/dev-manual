export const DEPLOY = [
  {
    title: `Централизованная обработка ошибок`,
    text1: `До этого момента мы уделяли мало внимания ошибкам, которые возвращало наше API, и отправляли клиенту ошибку прямо там, где она возникала:`,
    code1: {
      lang: "javascript",
      value: `try {
  payload = jwt.verify(token, 'some-secret-key');
} catch (err) {
  // возникла ошибка,
  // тут же отправим её, выставив статус
  return res
    .status(401)
    .send({ message: 'Необходима авторизация' });
}`,
    },
    text2: `Это приводит к тому, что код обработки ошибок дублируется в разных местах, и, если мы решим поменять формат возвращаемой ошибки, например, добавить в JSON ещё какое-то поле, нам придётся исправлять код несколько раз.
Чтобы избежать этого, принято обрабатывать ошибки централизованно. Для этого нужно добавить приложению мидлвэр такого вида:`,
    code2: `app.use((err, req, res, next) => {
  // это обработчик ошибки
});`,
    text3: `Он отличается от обработчика запроса тем, что принимает не 3, а 4 параметра. Первый дополнительный параметр — это и есть ошибка.
Такой обработчик ошибки добавляют в последнюю очередь, после всех app.use. Обычно это делают где-то в конце файла app.js:`,
    code3: `// app.js
// весь код app.js
// здесь обрабатываем все ошибки
app.use((err, req, res, next) => {
  res.status(500).send({ message: 'На сервере произошла ошибка' });
});
app.listen(PORT);`,
    text4: `Но как перейти в этот обработчик ошибки при её возникновении?`,
    subtitle1: `Вызов next с аргументом`,
    text5: `Чтобы передать обработку запроса дальше, мы привыкли вызывать next без аргумента.
Если next при вызове передать аргумент, это произведёт совсем иной эффект — запрос перейдёт в обработчик ошибки:`,
    code4: {
      lang: "javascript",
      value: `// вызов next с любым аргументом
// передаст запрос в обработчик ошибки
next('Аргумент');`,
    },
    text6: `Несмотря на то, что next можно передать любой аргумент, хорошая практика передавать ему экземпляр ошибки:`,
    code5: `// вызываем next с аргументом-ошибкой
next(new Error('Ошибка авторизации'));`,
    text7: `В обработчике можно будет использовать сообщение, переданное экземпляру ошибки при создании:`,
    code6: {
      lang: "javascript",
      value: `app.use((err, req, res, next) => {
  res.send({ message: err.message });
});
// { "message": "Ошибка авторизации" }`,
    },
    text8: `С сообщением понятно, но как в обработчике ошибки выставить ей правильный статус?`,
    subtitle2: `Выставляем ошибке статус`,
    text9: `Самый очевидный способ выставить статус — записать в экземпляр ошибки дополнительное свойство и вызвать next:`,
    code7: `try {
  payload = jwt.verify(token, 'some-secret-key');
} catch (e) {
  const err = new Error('Необходима авторизация');
  err.statusCode = 401;
  next(err);
}`,
    text10: `Мы используем способ получше, сделав свои конструкторы ошибок. Самые частые ошибки нашего приложения это:
400, когда с запросом что-то не так;
401, когда что-то не так при аутентификации или авторизации;
404, например, когда мы не нашли ресурс по переданному _id;
Сделаем для этих ошибок свои конструкторы.`,
    subtitle3: `Собственные конструкторы ошибок`,
    text11: `Для ошибок, которые часто повторяются, удобно использовать свои конструкторы. Простейший конструктор 404 ошибки будет выглядеть так:`,
    code8: `// errors/not-found-err.js
class NotFoundError extends Error {
  constructor(message) {
    super(message);
    this.statusCode = 404;
  }
}
module.exports = NotFoundError;`,
    text12: `Всё, что делает этот конструктор, — наследует от стандартной ошибки и выставляет свойство statusCode.
После создания конструктора NotFoundError, его можно импортировать в другие места кода и использовать вместе с инструкцией throw:`,
    code9: `const NotFoundError = require('./errors/not-found-err');
module.exports.getProfile = (req, res, next) => User
  .findOne({ _id: req.params.userId })
  .then((user) => {

  if (!user) {
    // если такого пользователя нет,
    // сгенерируем исключение
    throw new NotFoundError('Нет пользователя с таким id');
  }
  res.send(user);
})
// ...`,
    text13: `Инструкция throw генерирует исключение и обработка кода переходит в следующий блок catch, поэтому не забудьте его добавить.
Это можно сделать изящно:`,
    code10: `const NotFoundError = require('./errors/not-found-err');
module.exports.getProfile = (req, res, next) => User
  .findOne({ _id: req.params.userId })
  .then((user) => {

    if (!user) {
      throw new NotFoundError('Нет пользователя с таким id');
    }
    res.send(user);
  })
  .catch(next); // добавили catch`,
    text14: `Такая запись catch эквивалентна следующей:`,
    code11: `.catch(err => next(err));`,
    text15: `Получается, что next будет вызван с аргументом-ошибкой и запрос перейдёт в обработчик ошибки, но уже со статусом и сообщением:`,
    code12: `app.use((err, req, res, next) => {
  res.status(err.statusCode).send({ message: err.message });
});`,
  },
  {
    title: `Три важных правила централизованной обработки ошибок`,
    subtitle1: `1. Всегда завершайте цепочки промисов блоком catch.`,
    text1: `Передавайте в catch функцию next и добавляйте обработчик ошибки где-то в конце app.js.
Если цепочка промисов не завершена блоком catch, это приведёт к так называемому Unhandled promise rejection (англ. «необработанное отклонение промиса»). В будущих версиях Node.js — Node завершит свою работу и приложение упадёт.`,
    subtitle2: `2. Не используйте throw в завершающих блоках catch. Throw переводит обработку в следующий блок catch.`,
    text2: `Если использовать throw в последнем блоке catch, переходить ему будет некуда и возникнет Unhandled promise rejection.`,
    subtitle3: `3. Если в обработчик пришла ошибка без статуса, возвращайте ошибку сервера.`,
    text3: `Мы создали свои конструкторы ошибок. Теперь, когда нам нужно вернуть клиенту ошибку, мы конструируем экземпляр нужной ошибки и генерируем исключение с помощью throw.
Throw переводит обработку в блок catch, где его поджидает next. Кажется, всё в порядке, но есть один момент:
обработка может перейти в блок catch не по причине того, что мы использовали throw, а по какой-то другой.
Например, исключение может возникнуть при обращении в базу данных или наш код может просто-напросто упасть.
Если ошибка сгенерирована не нами, у неё не будет свойства statusCode:`,
    code1: `app.use((err, req, res, next) => {
  console.log(err.statusCode); // undefined
});`,
    text4: `В этом случае будем считать произошедшее ошибкой сервера, возвращать 500 статус и стандартное сообщение:`,
    code2: `app.use((err, req, res, next) => {
  // если у ошибки нет статуса, выставляем 500
  const { statusCode = 500, message } = err;
  res
    .status(statusCode)
    .send({
      // проверяем статус и выставляем сообщение в зависимости от него
      message: statusCode === 500
        ? 'На сервере произошла ошибка'
        : message
    });
});`,
  },
  {
    title: `Валидация приходящих на сервер данных`,
    text1: `Мы уже имплементировали валидацию, определив схему модели mongoose:`,
    code1: `const userSchema = new Schema({
  email: {
    type: String,
    required: true,
    unique: true,
    ...
});`,
    text2: `Если оставить валидацию только на этом уровне, приложение будет легко атаковать. Например, DDoS-атакой.
Ведь чтобы такая валидация запустилась, должен запуститься и код контроллера.
Код контроллера может непреднамеренно упасть, если клиент пришлёт не то тело запроса, которое мы от него ожидаем.
Также в контроллере могут быть CPU-интенсивные операции, например хеширование пароля.
Таким образом, злоумышленник может посылать много запросов, которые будут нагружать процессор или, того хуже, ронять наше приложение.
Поэтому принято валидировать входящий запрос и, если клиент присылает не то, что мы от него ждём, контроллер просто не запускается, а клиент получает ошибку. Для этого запрос описывают схемой.`,
    subtitle1: `Joi и celebrate`,
    text3: `Joi — популярная Node.js библиотека для валидации данных. Она позволяет описывать данные в интуитивно понятном виде:`,
    code2: {
      lang: "javascript",
      value: `{
  body: Joi.object().keys({
    email: Joi.string().required().email(),
    password: Joi.string().required().min(8),
    name: Joi.string().required().min(2).max(30),
    age: Joi.number().integer().required().min(18),
    about: Joi.string().min(2).max(30),
  })
}`,
    },
    text4: `Такое описание говорит, что body должно быть объектом с ключами:
email — строка, обязательное поле, должно соответствовать паттерну почты;
password — обязательная строка, минимум 8 символов;
name — обязательная строка от 2 до 30 символов;
age — число, целое, обязательное, минимально возможное значение — 18;
about — строка от 2 до 30 символов.
Чтобы подключить валидацию Joi в качестве мидлвэр, мы будем использовать библиотеку celebrate.
Перед использованием её нужно установить в проект, после чего импортировать и подключить как мидлвэр к роуту:`,
    code3: {
      lang: "javascript",
      value: `const { celebrate, Joi } = require('celebrate');
router.post('/posts', celebrate({
  body: Joi.object().keys({
    title: Joi.string().required().min(2).max(30),
    text: Joi.string().required().min(2),
  }),
}), createPost);`,
    },
    text5: `Такой мидлвэр валидирует тело запроса. В нём должно быть два поля — title и text.
Если тело запроса не пройдёт валидацию, контроллер createPost вообще не запустится.
Кроме тела запроса celebrate позволяет валидировать заголовки, параметры или req.query:`,
    code4: {
      lang: "javascript",
      value: `const { celebrate, Joi } = require('celebrate');
router.delete('/:postId', celebrate({
  // валидируем параметры
  params: Joi.object().keys({
    postId: Joi.string().alphanum().length(24),
  }),
  headers: Joi.object().keys({
    // валидируем заголовки
  }),
  query: Joi.object().keys({
    // валидируем query
  }),
}), deletePost);`,
    },
    text6: `По умолчанию Joi не допускает полей, которые не перечислены в объекте валидации.
Чтобы изменить это поведение, нужно после вызова метода keys вызвать метод unknown с аргументом true:`,
    code5: {
      lang: "javascript",
      value: `const { celebrate, Joi } = require('celebrate');
router.delete('/:postId', celebrate({
  headers: Joi.object().keys({
    // валидируем заголовки
  }).unknown(true),
}), deletePost);`,
    },
    subtitle2: `Ошибки`,
    text7: `Если запрос не проходит описанную валидацию, celebrate передаст его дальше, но не в контроллер, а в обработчик ошибки.
Чтобы отправить клиенту ошибку, в celebrate есть специальный мидлвэр — errors:`,
    code6: `// app.js
const { errors } = require('celebrate');
// ...
// обработчики ошибок
app.use(errors()); // обработчик ошибок celebrate
// наш централизованный обработчик
app.use((err, req, res, next) => {
  // ...
});`,
    text8: `errors() будет обрабатывать только ошибки, сгенерированные celebrate.
Все остальные ошибки он передаст дальше, где их перехватит централизованный обработчик.
Статус ошибки, которую возвращает celebrate, — 400, а тело ответа имеет вид:`,
    code7: {
      lang: "javascript",
      value: `{
  "statusCode": 400,
  "error": "Bad Request",
  "message": "child \\"name\\" fails because [\\"name\\" is required]",
  "validation": {
    "source": "body",
    "keys": [
      "name"
    ]
  }
}`,
    },
    text9: `Поле message позволяет клиенту понять, что не так с его запросом.
В данном случае celebrate сообщает, что в теле запроса отсутствует обязательное поле name.`,
    subtitle3: `Ссылки`,
    link: { uri: "https://joi.dev/api/", text: "Документация Joi" },
    link: {
      uri: "https://github.com/arb/celebrate",
      text: "Документация celebrate",
    },
  },
  {
    title: `Сбор логов`,
    text1: `В предыдущих уроках мы попытались застраховать себя от ошибок. Но всех ошибок не избежать.
Представьте ситуацию: пользователь написал в поддержку небольшой социальной сети, бэкенд которой разрабатываете вы.
Пользователь пожаловался, что у него не работает удаление постов.
Агент поддержки описал вам проблему. Вы тут же проверили функцию удаления постов и у вас всё сработало корректно — пост удалился.
Что сделать в этой ситуации? Можно ответить пользователю фразой «у нас всё работает», но это не решит его проблему.
Расстроенный, он уйдёт от нас к конкурентам. Как проанализировать почему в запросе пользователя происходит ошибка, если у нас нет доступа к его компьютеру? Что делать в ситуации, если сервер ведёт себя не так, как мы от него ожидаем?
В этом помогут логи.`,
    subtitle1: `Что такое логи`,
    text2: `Логи — информация о том, что происходит на сервере.
В простейшем случае — это журнал записи запросов к серверу и его ответов на эти запросы.
Если мы будем записывать запросы и ответы, то в случае какого-то отклонения от нормальной работы сможем проанализировать, что не так.
Логгирование поможет лучше понимать, что происходит на сервере. Реализуем его.`,
    subtitle2: `Winston`,
    text3: `Есть много решений для сбора логов. Мы воспользуемся одним из самых популярных и гибких — winston. Winston — это библиотека для логгирования. Чтобы с ней было удобно работать в express, кроме неё нам понадобится мидлвэр express-winston.
После установки этих двух пакетов (winston и express-winston), их можно импортировать.
Всю работу будем вести в файле middlewares/logger.js:`,
    code1: `// импортируем нужные модули
const winston = require('winston');
const expressWinston = require('express-winston');`,
    text4: `После этого нужно создать логгер. Мы будем логгировать два типа информации — запросы к серверу и ошибки, которые на нём происходят.`,
    code2: {
      lang: "javascript",
      value: `// Для создания логгера запросов воспользуемся функцией logger модуля expressWinston:
// middlewares/logger.js
const winston = require('winston');
const expressWinston = require('express-winston');
// создадим логгер запросов
const requestLogger = expressWinston.logger({
  transports: [
    new winston.transports.File({ filename: 'request.log' }),
  ],
  format: winston.format.json(),
});`,
    },
    text5: `Обратите внимание на опции, которые мы передаём при создании. Опция transports отвечает за то, куда нужно писать лог.
В нашем случае это файл request.log. Также transports — массив, в него можно записать и другие транспорты.
Например, логи можно писать в консоль или в сторонний сервис аналитики, но мы ограничимся файлом.
Вторая опция — format отвечает за формат записи логов. Мы указали json, потому что его удобно анализировать.
Логгер запросов создан, теперь сделаем логгер ошибок. Он нужен, чтобы в случае возникновения ошибки, в лог записывалась информация о ней — имя ошибки, сообщение и её стектрейс.
Логгер ошибок создаётся методом errorLogger модуля expressWinston:`,
    code3: {
      lang: "javascript",
      value: `// middlewares/logger.js
const winston = require('winston');
const expressWinston = require('express-winston');
const requestLogger = expressWinston.logger({
  transports: [
    new winston.transports.File({ filename: 'request.log' }),
  ],
format: winston.format.json(),
});
// логгер ошибок
const errorLogger = expressWinston.errorLogger({
  transports: [
    new winston.transports.File({ filename: 'error.log' }),
  ],
  format: winston.format.json(),
});`,
    },
    text6: `Ошибки мы пишем в отдельный файл — error.log.
После создания логгеров их нужно экспортировать:`,
    code4: `module.exports = {
  requestLogger,
  errorLogger,
};`,
    text7: `А затем импортировать в app.js:`,
    code5: `const { requestLogger, errorLogger } = require('./middlewares/logger');`,
    text8: `Пришло время подключить логгеры как мидлвэр. Логгер запросов нужно подключить до всех обработчиков роутов:`,
    code6: {
      lang: "javascript",
      value: `app.use(requestLogger); // подключаем логгер запросов
// за ним идут все обработчики роутов
app.post('/signup', createUser);
app.post('/signin', login);
app.use('/users', usersRouter);
app.post('/posts', postsRouter);`,
    },
    text9: `errorLogger нужно подключить после обработчиков роутов и до обработчиков ошибок:`,
    code7: {
      lang: "javascript",
      value: `app.use(logger);
app.post('/signup', createUser);
app.post('/signin', login);
app.use('/users', usersRouter);
app.post('/posts', postsRouter);
app.use(errorLogger); // подключаем логгер ошибок
app.use(errors()); // обработчик ошибок celebrate
// централизованный обработчик ошибок
app.use((err, req, res, next) => {
  // ...
});`,
    },
    text10: `Логгеры подключены.
Теперь при запросе к серверу создастся файл request.log, в него в формате json запишется часть данных из запроса и ответа.
Если на сервере произойдёт ошибка, создастся файл error.log, туда запишется часть данных запроса и ответа, и информация о произошедшей ошибке. Это будет только часть данных, ведь в лог не запишется тело запроса, и записывать её в файл в незашифрованном виде небезопасно. Такое поведение по умолчанию можно изменить.
Если в вашем проекте это потребуется, разберитесь в документации самостоятельно по ссылкам в конце урока.
По умолчанию это сделано так, потому что в теле может содержаться конфиденциальная информация, например, пароль пользователя,`,
    subtitle3: `gitignore`,
    text11: `Последний момент: не забудьте добавить файлы логов в .gitignore, чтобы они не добавлялись в репозиторий.
Сделать это можно, добавив в .gitignore одну строчку:`,
    code8: `*.log`,
    text12: `Теперь все файлы с расширением log невидимы для git.`,
    subtitle4: `Ссылки`,
    link: {
      uri: "https://www.npmjs.com/package/express-winston",
      text: "Документация express-winston",
    },
    link: {
      uri: "https://github.com/winstonjs/winston",
      text: "Документация winston",
    },
    link: {
      uri: "https://stackify.com/winston-logging-tutorial/",
      text: "Подробный туториал по winston",
    },
  },
  {
    title: `Создаём удалённый сервер`,
    text1: `До настоящего момента мы разрабатывали бэкенд локально, то есть доступ к нему был только у нас. Рано или поздно наступает момент, когда код нужно «выкатывать в продакшн», то есть загружать на публичный сервер, чтобы другие люди могли им пользоваться.
Есть несколько опций, где разместить наш код. Первая — купить железо и поставить сервер у себя в гараже.
В этом случае придётся самостоятельно настраивать сеть, заниматься безопасностью и поддержкой стабильности сервера.
Если вы не хотите этого делать, есть вторая опция — аренда облачного сервера.
Это готовый сервер, который можно создать и сконфигурировать под себя за несколько минут.
При этом его поддержкой, настройкой и безопасностью занимается компания, которая сдаёт этот сервер в аренду.
Вот несколько популярных решений облачных серверов:`,
    text2: `      Amazon Web Services;
      Google Compute Cloud;
      Яндекс.Облако.`,
    text3: `Мы воспользуемся последним по двум причинам:
Яндекс.Облако предоставляет грант на бесплатное использование сервиса. Этот грант полностью покроет нужды нашего обучения.
Сервера Яндекс Облака удовлетворяют закону о персональных данных и нам не придётся об этом думать.`,
    subtitle1: `Создайте аккаунт в Яндекс Облаке`,
    text4: `Зайдите на https://cloud.yandex.ru и залогиньтесь через аккаунт Яндекса. Затем войдите в консоль:`,
    image1: "image67.png",
    text5: `После регистрации вы можете активировать пробный период. На время этого периода Яндекс Облако предоставляет вам грант на 4000 руб.
Грант действует 60 дней и разбит на 2 части: 1000 рублей и 3000 рублей.
1000 рублей можно использовать для создания виртуальных машин, а остальные 3000 — на другие сервисы облака.
Для деплоя бэкенда будем использовать виртуальные машины Яндекс Облака, то есть на наши нужды есть 1000 рублей стартового гранта.
Остальное можете использовать на своё усмотрение или не использовать вовсе.`,
    link: {
      uri: "https://cloud.yandex.ru/docs/free-trial/concepts/usage-grant",
      text: "Подробная информация о предоставлении гранта",
    },
    subtitle2: `Создайте платёжный аккаунт`,
    text6: `Чтобы иметь возможность пользоваться Яндекс Облаком, нужно создать платёжный аккаунт.
Перейдите в раздел «Billing» и нажмите «Создать аккаунт».
В открывшемся окне введите свои данные, данные своей карты и нажмите «Активировать».
Мы понимаем скепсис по поводу ввода данных карты.
Для нас это необходимо, чтобы иметь возможность создать сервер и задеплоить на него бэкенд.
Стартового гранта в 1000 рублей хватит примерно на 2 месяца, это полностью покрывает срок нашего обучения.
Дальше у вас будет возможность остаться в Облаке или выбрать другую платформу.
Создайте виртуальную машину
Чтобы начать создавать виртуальную машину, зайдите в `,
    link: {
      uri: "https://console.cloud.yandex.ru/",
      text: "консоль Яндекс Облака",
    },
    text7: `Нам понадобится сервис Compute Cloud. В левом меню кликните на него:`,
    image2: "image68.png",
    text8: `Теперь нужно создать виртуальную машину. Кликните на «Создать ВМ»:`,
    image3: "image69.png",
    text9: `Введите название проекта на ваш выбор, в качестве публичного образа выберите Ubuntu 18.04 lts:`,
    image4: "image70.png",
    text10: `Дискам и вычислительным ресурсам оставьте настройки по умолчанию, этого хватит для начала:`,
    image5: "image71.png",
    text11: `Ваши настройки должны совпадать с теми, что на скриншоте. Если что-то отличается, приведите это в соответствие со скриншотом.
В блоке «Доступ» в поле «Логин» введите имя пользователя, по которому будете заходить на сервер.
Оно может быть произвольным, но должно соответствовать правилам, которые можно прочитать, наведя курсор на знак вопроса слева.
В поле SSH-ключ скопируйте ваш SSH-ключ, он понадобится для подключения к серверу:`,
    image6: "image72.png",
    text12: `Вы можете ввести SSH-ключ, созданный в теме про Github, или создать новый.
После того как всё сделали, нажмите «Создать BM». Облаку понадобится какое-то время, чтобы создать машину.
Примерно через минуту её статус изменится на “Running” — это значит, что машина создана:`,
    image7: "image73.png",
  },
  {
    title: `Подключение к серверу`,
    text1: `Чтобы подключиться к серверу, понадобится публичный IP и логин, который мы указали при создании виртуальной машины.`,
    image1: "image74.png",
    text2: `Скопировав публичный IP, зайдите в командную строку и введите команду (замените praktukum и 84.201.130.70 на свои логин и IP):`,
    code1: {
      lang: "bash",
      value: `ssh loki@130.193.46.160`,
    },
    text3: `Если это первое подключение к серверу, вы увидите фразу:`,
    code2: {
      lang: "bash",
      value: `The authenticity of host '84.201.130.70 (84.201.130.70)' can't be established.
ECDSA key fingerprint is SHA256:gGz1AULJpNptRRaqLz2FQTDf/IRxSGPA0vvmmXWy/6I.
Are you sure you want to continue connecting (yes/no)?`,
    },
    text4: `Введите “yes” и нажмите Enter. Вам будет предложено ввести пароль от приватного ключа, введите его и снова нажмите Enter.
Если пароль правильный, вы окажетесь на удалённом сервере:`,
    image2: "image75.png",
    text5: `Отлично! Мы на сервере. Освойтесь, введя несколько команд, а в следующем уроке мы установим всё необходимое для работы нашего API.
Выйти из сервера можно сочетанием клавиш Ctrl+D`,
  },
  {
    title: `Устанавливаем на сервер всё необходимое`,
    text1: `В предыдущем уроке мы подключились к удалённому серверу по SSH.
Теперь необходимо установить на него всё, что нужно для работы нашего API, а нужно нам не так уж и много:
Node.js, чтобы можно было запустить приложение;
Mongo DB, чтобы работал сервер с базой данных;
git, чтобы загружать на сервер код.
Установив всё это, уже к концу урока мы сможем запустить созданный нами API на сервере.`,
    subtitle1: `Установите Node.js`,
    text2: `Сначала проверьте версию Node.js, которая установлена у вас локально. Для этого введите в командную строку команду:`,
    code1: `node -v`,
    text3: `В командной строке появится номер версии — три числа, разделённые точками.
Первое число — это мажорная версия. Версия Node, которую мы установим на сервер, должна иметь такую же мажорную версию.
Так инфраструктура нашего сервера будет близка к той, в которой мы разрабатывали приложение, а значит, оно будет так же работать.
Теперь зайдите на сервер, созданный в прошлом уроке. И введите по очереди две следующие команды.
В первой команде замените 11 на мажорную версию, которую только что узнали:`,
    code2: {
      lang: "bash",
      value: `# в этой команде замените 11 на ту мажорную
# версию Node, которая стоит у вас локально
curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash -
# устанавливаем Node.js
sudo apt-get install -y nodejs`,
    },
    text4: `Первая команда добавляет официальный дистрибутив Node.js к нам в систему, а вторая устанавливает его.
После того как вторая команда закончит установку, проверьте, что нужная версия Node установлена на сервере:`,
    code3: `node -v`,
  },
  {
    title: `Установите Mongo`,
    text1: `Чтобы установить mongo на Ubuntu, воспользуемся официальной инструкцией.
Мы не будем объяснять, что значит каждая из этих команд, это выходит за рамки текущего курса.`,
    code1: `# 1.
wget -qO - https://www.mongodb.org/static/pgp/server-4.2.asc | sudo apt-key add -
# 2.
echo "deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.2 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.2.list
# 3.
sudo apt-get update
# 4.
sudo apt-get install -y mongodb-org`,
    text2: `После того как последняя команда закончила свою работу, проверим, установилась ли mongo. Следующая команда запустит mongo-сервер:`,
    code2: {
      lang: "bash",
      value: `sudo service mongod start`,
    },
    text3: `И последнее. Сделаем так, чтобы mongo-сервер запускался автоматически даже при перезагрузке удалённой машины:`,
    code3: `sudo systemctl enable mongod.service`,
    text4: `Теперь у вас должна быть возможность войти в mongo shell, введя команду:`,
    code4: `mongo`,
    text5: `Если всё в порядке, mongo shell запустится:`,
    image1: "image76.png",
    text6: `Чтобы выйти из него, нажмите Ctrl+C.`,
    subtitle1: `Установите git`,
    text7: `Осталось установить git, он позволит нам легко обновлять код на сервере. В его установке помогут две команды:
Скопировать кодBASH`,
    code5: `# 1.
sudo apt update
# 2.
sudo apt install git`,
    text8: `Вторая команда в процессе установки задаст вам вопрос:`,
    code6: {
      lang: "bash",
      value: `After this operation, 76.2 MB of additional disk space will be used
Do you want to continue? [Y/n]`,
    },
    text9: `Введите y (“yes”) и нажмите Enter.
После установки проверьте, всё ли в порядке командой:`,
    code7: {
      lang: "bash",
      value: `git --version`,
    },
    text10: `Она должны вывести на экран установленную версию git.`,
    subtitle2: `Запустите сервер`,
    text11: `Перед тем как запустить сервер, нужно загрузить на него наш код.
Для этого клонируйте git репозиторий с кодом в папку вашего пользователя.
В нашем случае это /home/praktikum:`,
    image2: "image77.png",
    text12: `Клонируйте репозиторий самостоятельно, вы уже умеете это делать. После этого войдите в папку проекта, установите зависимости:`,
    code8: `npm install`,
    text13: `и запустите сервер:`,
    code9: {
      lang: "bash",
      value: `npm start`,
    },
    text14: `Сервер запущен, скорее открывайте Postman.`,
    subtitle3: `Проверьте, что всё работает`,
    text15: `В Postman попробуйте сделать какой-нибудь запрос к удалённому серверу.
Замените IP-адрес на свой и не забудьте добавить запросу 3000 порт:`,
    code10: `GET http://84.201.130.70:3000/users`,
    text16: `Сервер отвечает ошибкой авторизации, но главное, что он отвечает. Теперь попробуйте выйти из сервера, нажав Ctrl+C, и затем Ctrl+D.
Отправив тот же самый запрос через Postman, вы увидите, что ответа больше нет.
Дело в том, что выйдя с сервера, мы остановили процесс, в котором работала Node.js.
В следующем уроке вы узнаете как сделать так, чтобы при выходе приложение продолжало работать.`,
  },
  {
    title: `Как сделать так, чтобы приложение работало всегда?`,
    text1: `Node.js работает в определённом процессе на компьютере.
Когда мы нажимаем Ctrl+C, этот процесс завершается и приложение перестаёт работать.
Чтобы этого не случалось, нужно воспользоваться менеджером процессов. Один из самых распространённых — pm2.`,
    subtitle1: `Установка и запуск`,
    text2: `Зайдите на сервер и установите pm2 как глобальный модуль:`,
    code1: `sudo npm install pm2 -g`,
    text3: `Теперь можно запустить приложение с помощью pm2. Перейдите в папку проекта и используйте команду:`,
    code2: {
      lang: "bash",
      value: `pm2 start app.js`,
    },
    text4: `pm2 запустил приложение, по умолчанию взяв имя запускаемого файла без расширения:`,
    image1: "image78.png",
    text5: `Теперь, если даже мы разорвём соединение с сервером, приложение продолжит работать.
Второй важный момент: если наше приложение упадёт, pm2 его поднимет, а это приятно.`,
    subtitle2: `Делаем приложение ещё стабильнее`,
    text6: `Сделаем так, чтобы приложение запускалось даже при перезагрузке сервера. Для этого введите команду:`,
    code3: `pm2 startup`,
    text7: `В ответ вы получите примерно такое сообщение:`,
    code4: `To setup the Startup Script, copy/paste the following command:
sudo env PATH=$PATH:/usr/bin /usr/lib/node_modules/pm2/bin/pm2 startup systemd -u praktikum --hp /home/praktikum`,
    text8: `Cкопируйте команду, начиная с sudo env, в командную строку и нажмите Enter. Последнее, что нужно сделать, — ввести команду:`,
    code5: `pm2 save`,
    text9: `Теперь даже в случае перезагрузки сервера, приложение автоматически запустится.`,
    subtitle3: `Ссылки`,
    link: {
      uri: "http://pm2.keymetrics.io/docs/usage/pm2-doc-single-page/.",
      text: "Документация модуля pm2",
    },
    link: { uri: "Pm2 на npm", text: "https://www.npmjs.com/package/pm2" },
  },
  {
    title: `Прикрепляем доменное имя`,
    text1: `Пока мы можем обратиться к серверу только по IP-адресу, но в реальном мире обычно используется доменное имя.
В этом уроке вы создадите и прикрепите его к IP-адресу вашего сервера.
Обычно создание домена — платная услуга. А пока учитесь — воспользуйтесь нашим сервисом по ссылке бесплатно.
Вам потребуется заполнить всего два поля:`,
    image1: "image79.png",
    text2: `Первое, что нужно сделать, — указать доменное имя, которое хотели бы получить. Введите желаемое имя в первое поле ввода.
Второе — создать привязку домена и вашего сервера в Яндекс.Облаке. Это можно сделать с помощью A-записи.
Она связывает домен и сервер по публичному IP-адресу. Введите публичный IP-адрес сервера в Яндекс.Облаке во второе поле.
Используйте такой формат записи:`,
    code1: `000.000.000.000`,
    text3: `Как только все данные будут введены, нажмите «Создать».
Если запрос на создание домена прошёл успешно, появится соответствующее сообщение:`,
    image2: "image80.png",
    text4: `Теперь DNS службе нужно некоторое время, чтобы обновить данные о домене. Обычно это занимает до 10 минут.
Поэтому через 10–15 минут зайдите в Postman и попробуйте отправить запрос:`,
    code2: `POST http://domainname.students.nomoreparties.co:3000/signup`,
    text5: `Если домен прикрепился, вы получите ответ вашего сервера, если нет, нужно подождать ещё.
Обратите внимание, что мы по-прежнему указываем 3000 порт, так как именно на нём запущен наш Node сервер.
Если убрать порт из запроса, ответа не будет. В следующем уроке разберёмся, почему так происходит и как это исправить.`,
  },
  {
    title: `Разбираемся с портами. HTTP-сервер nginx`,
    text1: `В предыдущем уроке мы столкнулись с проблемой: если отправить на сервер запрос без указания порта, сервер не ответит.
Это происходит потому, что наше приложение запущено на 3000 порту, а запрос без указания порта по умолчанию идёт на 80-й.
Мы могли бы попробовать это исправить, изменив порт в коде приложения:`,
    code1: {
      lang: "javascript",
      value: `app.listen(80);`,
    },
    text2: `Если это сделать и запустить приложение на сервере в облаке, будет ошибка:`,
    code2: `Error: listen EACCES 0.0.0.0:80`,
    text3: `Дело в том, что Node.js по умолчанию не может взаимодействовать с портами ниже 1024.
И это даже не ограничение Node.js, а ограничение Unix-систем, которое не разрешает процессу, запущенному без прав суперпользователя, взаимодействовать с такими портами. Получается, что ошибку можно исправить, запустив приложение с правами суперпользователя.
Для этого нужно добавить команду sudo:`,
    code3: `sudo node app.js`,
    text4: `Тогда Node.js приложение сможет работать на 80 порту, но при этом станет гораздо менее безопасным.
Если злоумышленник каким-то образом сумеет запустить код на вашем сервере, то у него будет полный доступ к машине.
А если Node.js приложение будет работать под обычным пользователем и злоумышленник как-то запустит в нём свой код,
у него будет много системных ограничений. Он уже не сможет делать с машиной всё, что пожелает.
Поэтому добавление sudo — не наш вариант.
Нам нужно научиться как-то перенаправить запрос с 80 порта на 3000, где работает наш Node.js сервер. Это можно сделать с помощью nginx.`,
    subtitle1: `Nginx`,
    text5: `Nginx — это HTTP-сервер. Он умеет раздавать статические файлы, перенаправлять запросы, кешировать результат.
Со всеми этими задачами nginx справляется очень быстро. Но на nginx не создать сервер с какой-то сложной логикой, это задача Node.
Поэтому Node и nginx работают в связке:`,
    text6: `      если нужно отдать статический файл или перенаправить запрос куда-то, лучше поручить это nginx;
      если нужно исполнить какую-то логику — это сделает Node;`,
    text7: `Мы будем использовать nginx как обратный прокси-сервер. Обратный прокси-сервер — это сервер, который принимает запросы извне и перенаправляет их во внутреннюю сеть. Получив из внутренней сети ответ, nginx направит его клиенту.
Наша задача сделать так, чтобы nginx слушал запросы на 80 порту и перенаправлял их на 3000 порт, где работает Node.js.
Зайдите на удалённый сервер и установите nginx:`,
    code4: {
      lang: "javascript",
      value: `sudo apt-get update
sudo apt-get install nginx`,
    },
    text8: `После установки nginx нужно настроить файрвол. Файрвол — прослойка между нашим сервером и внешним миром, которая решает какие запросы пускать дальше, а какие отклонять.
В операционной системе Ubuntu по умолчанию установлен файрвол — ufw. Сконфигурируем его, разрешив некоторые виды трафика.
Для этого используйте команды:`,
    code5: `sudo ufw allow 'Nginx Full'
sudo ufw allow OpenSSH`,
    text9: `sudo ufw allow 'Nginx Full' открывает на текущей машине два порта — 80 и 443. На эти порты приходят http и https запросы к серверу.
OpenSSH открывает порт 22 — это соединение по ssh, чтобы мы могли подключаться к серверу через консоль и при работающем файрволе.
После этого нужно включить файрвол:`,
    code6: `sudo ufw enable`,
    text10: `и запустить nginx:`,
    code7: {
      lang: "bash",
      value: `sudo systemctl start nginx`,
    },
    text11: `Откройте в браузере адрес своего сервера. Вы должны увидеть:`,
    image: "image81.png",
    text12: `Это значит, что nginx запустился и работает на 80 порту. Но сейчас он просто отдаёт стандартную html-страницу, а мы хотим,
чтобы запросы перенаправлялись. Для этого нужно изменить конфигурационный файл nginx. В командной строке введите команду:`,
    code8: `sudo nano /etc/nginx/sites-enabled/default
# sudo значит запустить команду как суперпользователь
# nano — это текстовый редактор
# /etc/nginx/sites-enabled/default — путь к конфигурационному файлу nginx`,
    text13: `Удалите содержимое этого файла и вставьте туда такую конфигурацию:`,
    code9: {
      lang: "bash",
      value: `server {
  listen 80;
  server_name diplom.students.nomoreparties.xyz www.diplom.students.nomoreparties.xyz;
  location / {
    proxy_pass http://localhost:3000;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection 'upgrade';
    proxy_set_header Host $host;
    proxy_cache_bypass $http_upgrade;
  }
}`,
    },
    text14: `Такая конфигурация говорит, что слушать запросы необходимо на 80 порту и перенаправлять их на http://localhost:3000, то есть на 3000 порт внутренней сети. Кроме перенаправления запроса конфигурация выставляет некоторые дополнительные заголовки.
Также в конфигурационном файле есть блок server_name. В нём пропишите доменное имя, зарегистрированное в предыдущем уроке, и, через пробел, его же с приставкой www.. Тогда такая конфигурация будет перенаправлять все запросы с:`,
    code10: `http://mestoapp.gq;
http://www.mestoapp.gq.`,
    text15: `нашему Node.js приложению на 3000 порт.
Запоминать эти команды необязательно, их всегда можно подсмотреть в документации.
После того как всё сделаете, нажмите Ctrl+X. Nano спросит у вас, хотите ли вы сохранить изменения, нажимайте y и Enter.
После обновления конфигурации nginx необходимо перезапускать:`,
    code11: `sudo systemctl restart nginx`,
    text16: `Теперь попробуйте послать из Postman запрос без указания порта:`,
    code12: `POST http://mestoapp.gq`,
    text17: `Пришел ответ от Node.js сервера — мы настроили проксирование запросов через nginx!`,
  },
  {
    title: `Шифрование данных. Протокол HTTPS`,
    text1: `Между клиентом и сервером происходит обмен информацией.
Часто эта информация конфиденциальна и нужно сделать всё, чтобы у злоумышленника не было доступа к ней.
Для этого информацию между клиентом и сервером передают в зашифрованном виде.
Шифрование осуществляется при помощи SSL-сертификата. Разберёмся, что это.`,
    subtitle1: `Что такое сертификат`,
    text2: `SSL расшифровывается как Secure Socket Layer (англ. «уровень защищённых сокетов»).
С помощью SSL-сертификата информация, передаваемая между клиентом и сервером, шифруется.
Теперь, даже если злоумышленнику удастся её перехватить, он не сможет извлечь из этого пользы, так как информация зашифрована.
SSL-сертификат выдаётся так называемой Certificate Authority или CA (англ. «центр сертификации»).
CA — третья сторона, которой клиент и сервер могут доверять. Она выдаёт сертификат на основе доменного имени и информации о сервере.
Сертификат выпускается на доменное имя и его нужно создавать, зайдя на сервер. Проверив доменное имя и IP-адрес сервера,
куда оно указывает, CA убедится, что сертификат выпускает именно владелец домена, и выдаст его.
После этого вся передаваемая информация может быть зашифрована и подписана с использованием выпущенного сертификата.
А клиент сможет убедиться, что подписана информация именно сертификатом сервера и никаким другим.
Так клиент и сервер смогут шифровать информацию и проверять, кем она зашифрована, это исключает изменение и подлог данных.
Некоторые CA выпускают сертификаты за деньги, но есть и бесплатные. Одна из самых популярных — Let's Encrypt.
Её сертификатом мы и воспользуемся.`,
    subtitle2: `Выпускаем сертификат`,
    text3: `SSL-сертификат от Letsencrypt можно выпустить специальной программой — certbot.
На сайте certbot есть описание процесса, как выпустить сертификат и сконфигурировать nginx, чтобы он его использовал.
Можете сделать это самостоятельно или воспользоваться дальнейшей инструкцией.
Зайдите на сервер и введите по очереди команды:`,
    code1: {
      lang: "bash",
      value: `sudo apt-get update
sudo apt-get install software-properties-common
sudo add-apt-repository universe
sudo add-apt-repository ppa:certbot/certbot
sudo apt-get update
sudo apt-get install certbot python-certbot-nginx`,
    },
    text4: `Теперь certbot установлен.`,
    subtitle3: `Подключаем сертификат`,
    text5: `Чтобы подключить выпущенный сертификат, введите команду:`,
    code2: `sudo certbot --nginx`,
    text6: `В процессе исполнения вам будет задано несколько вопросов:`,
    subtitle4: `Enter email address (англ. «введите почту»).`,
    text7: `Почта нужна для предупреждений, что сертификат пора обновить.`,
    subtitle5: `Please read the Terms of Service; (A)gree/(C)ancel: (англ. «прочитайте правила сервиса; принять/отклонить»).`,
    text8: `Прочитайте правила по ссылке и введите a. Затем нажмите Enter.`,
    subtitle6: `Would you be willing to share your email address with the Electronic Frontier Foundation?`,
    text9: `(англ. «хотите ли вы поделиться своей почтой с Фондом электронных рубежей»).
Отметьте на своё усмотрение y (да) или n (нет) и нажмите Enter.`,
    subtitle7: `Which names would you like to activate HTTPS for? (англ. «для каких доменных имён вы хотите включить https?»).`,
    text10: `Вам будет предложено два варианта: [mestoapp.gq](http://mestoapp.tk) и www.mestoapp.gq.
Это доменные имена, которые мы добавили в поле server_name конфигурации nginx в предыдущем уроке.
Ничего не вводя, нажмите Enter. Тогда https будет включён для обеих опций.`,
    subtitle8: `Please choose whether or not to redirect HTTP traffic to HTTPS? 1: No redirect, 2: Redirect`,
    text11: `(англ. «нужно ли перенаправлять http траффик на https, 1: не перенаправлять, 2: перенаправлять»). Выберите 1 и нажмите Enter.
В итоге сертификаты будут выпущены.
Также эта команда отредактирует конфигурацию nginx, добавив в неё нужные настройки и прописав пути к сертификату.
Не забудьте перезапустить nginx:`,
    code2: `sudo systemctl restart nginx`,
    text12: `Теперь весь трафик, приходящий на порт 443, — порт для https-запросов и ответов, будет шифроваться.
Откройте Postman и попробуйте отправить https-запрос — всё должно получиться.
Это значит, что сертификат успешно подключён и информация между клиентом и сервером передаётся в зашифрованном виде.`,
    subtitle9: `Обновление сертификата`,
    text13: `Выпущенный сертификат нужно обновлять минимум раз в 3 месяца. Для этого, когда придёт время, воспользуйтесь командой:`,
    code3: `sudo certbot renew --pre-hook "service nginx stop" --post-hook "service nginx start"`,
    text14: `Она обновит сертификат и перезапустит nginx.`,
  },
  {
    title: `Заливаем обновления на сервер`,
    text1: `Мы сделали почти всё: настроили сервер, развернули бэкенд, подключили сертификаты. Но разработка проекта на этом не заканчивается.
Возможно, в нём найдётся какой-то баг, который надо будет исправить, или мы решим внедрить новую функциональность, тогда код на сервере тоже придётся обновить.
В шестом уроке мы установили на сервер git. Все обновления кода мы загружаем на github, в ветку master.
Поэтому, чтобы обновить код, зайдите в папку с проектом на сервере и заберите последние изменения с github:`,
    code1: `git pull origin master`,
    text2: `После этого останется только перезагрузить pm2, чтобы изменения вступили в силу:`,
    code2: `pm2 restart app`,
    text3: `Процесс перезапустится и обновления вступят в силу.`,
    subtitle1: `Из какой ветки деплоить код на ревью`,
    text4: `Master — основная ветка проекта. В ней содержится стабильная версия кода, пригодная для деплоя.
Но при отправке проектной работы на ревью, вы пишете код в отдельной ветке.
Поэтому в проектной работе можно задеплоить код не из мастера, а из ветки, в которой ведёте работу.`,
  },
  {
    title: `Фронтенд и бэкенд на одном домене`,
    text1: `Вы научились деплоить бэкенд на сервере и прикреплять к этому серверу домен.
Теперь, когда необходимо послать запрос к API, для этого можно использовать доменное имя.
Ещё давно вы научились деплоить фронтенд на Github Pages, но фронтенд реальных проектов обычно хранят не на Github, а на каком-то сервере с красивым доменным именем. Поэтому нужно научиться делать так, чтобы при заходе на сайт с использованием доменного имени, пользователь видел фронтенд сайта, и при этом сохранялась возможность делать запросы к API.`,
    subtitle1: `Заливаем код фронтенда на сервер`,
    text2: `Залить код фронтенда можно точно так же, как мы делали это с бэкендом — через клонирование git-репозитория.
После того как репозиторий клонирован, нужно запустить на сервере процесс сборки, и когда он закончится, в папке dist будут файлы, готовые к раздаче.
Это можно и проще. Ведь в случае фронтенда на сервере нам нужна только готовая сборка, а репозиторий с исходным кодом понадобится только для разработки. Поэтому процесс может быть таким:
Осуществить сборку локально.
Скопировать папку dist на удалённый сервер.
Собирать фронтенд вы уже умеете, осталось придумать, где на сервере расположить папку с ним, и скопировать её туда. Для этого:
находясь на удалённом сервере, рядом с папкой, где храните бэкенд на сервере, создайте папку для фронтенда.
      Назовите её, например, news-frontend;
      соберите файлы локально;
      скопируйте файлы с локального компьютера на удалённый. Это можно сделать командой scp:`,
    code1: {
      lang: "bash",
      value: `scp -r ./build/* loki@130.193.46.160:/home/loki/news-frontend`,
    },
    text3: `В таком виде команда scp принимает одну опцию и несколько аргументов. Опция -r говорит, что папки нужно копировать рекурсивно.
Значит, если в папке dist есть вложенные папки, их содержимое тоже необходимо скопировать. Аргументы, которые принимает scp: ./dist/* — путь к локальным файлам или папкам, которые нужно скопировать. Dist/* означает, что необходимо взять все файлы из папки dist. praktikum@84.201.172.240:/home/praktikum/news-frontend — адрес удалённого сервера и папки на нём.
Важный момент: чтобы подключение к удалённому серверу было успешным, на нём должен быть наш SSH-ключ.
Для удобства можно добавить скрипт для деплоя в package.json проекта с фронтендом:`,
    code2: `"deploy": "npm run build && scp -r ./dist/* praktikum@84.201.172.240:/home/praktikum/news-frontend"`,
    text4: `Такой скрипт сначала соберёт файлы, а затем скопирует их на сервер.
Осталось научить сервер их раздавать.`,
    subtitle2: `Бэкенд на /api`,
    text5: `Первый способ организовать фронтенд и бэкенд на одном домене — разместить на самом домене фронтенд, а API разместить на специальном пути — /api.`,
    code3: `mestoapp.tk — фронтенд
mestoapp.tk/api — API`,
    text6: `Мы могли бы решить эту задачу только с использованием express:`,
    code4: {
      lang: "javascript",
      value: `// подключаем главный роутер приложения на /api
app.use('/api', require('../router'));
// раздаём папку с собранным фронтендом
app.use(express.static(path.join(__dirname, 'public')));`,
    },
    text7: `Это будет работать, но отдавать раздачу статичных файлов Node.js — не лучшая идея.
Node.js хорош в исполнении логики и в асинхронных операциях ввода/вывода. С раздачей статичных файлов лучше справляется nginx.
Он не только делает это быстрее, но и позволяет относительно несложно реализовать сжатие этих файлов.
Кроме этого, nginx работает в отдельном процессе и не загружает единственный поток Node.
Сконфигурируем nginx так, чтобы он отвечал за раздачу статики, а когда это необходимо, перенаправлял запросы Node.
Для этого нужно совсем немного — отредактировать уже готовый конфигурационный файл nginx. Зайдите на сервер и введите команду:`,
    code5: `sudo nano /etc/nginx/sites-enabled/default`,
    text8: `В текстовом редакторе nano откроется файл конфигурации nginx. У вас он будет выглядеть примерно так:`,
    code6: `server {
  listen 80;
  server_name mestoapp.tk www.mestoapp.tk;
  location / {
    proxy_pass http://localhost:3000;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection 'upgrade';
    proxy_set_header Host $host;
    proxy_cache_bypass $http_upgrade;
  }
  listen 443 ssl; # managed by Certbot
  ssl_certificate /etc/letsencrypt/live/mestoapp.tk/fullchain.pem; # managed by Certbot
  ssl_certificate_key /etc/letsencrypt/live/mestoapp.tk/privkey.pem; # managed by Certbot
  include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot
  ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot
}`,
    text9: `В нём нужно изменить всего несколько вещей. Первым делом разместим API на пути /api. Для этого откорректируем блок location, перенаправляющий запрос Node.js приложению. Сейчас он выглядит так:`,
    code7: `location / {
  proxy_pass http://localhost:3000;
  proxy_http_version 1.1;
  ...
}`,
    text10: `Заменим / на /api/:`,
    code8: `location /api/ {
  proxy_pass http://localhost:3000;
  proxy_http_version 1.1;
  ...
}`,
    text11: `Теперь все запросы, путь которых начинается с /api/, будут перенаправлены Node.js серверу. Обратите внимание на висячий слеш.
Он страхует от того, что API будут перенаправлены запросы вида: /api-some-more-words-after-api. Например:`,
    code9: `/api/hello/world — будет перенаправлен Node серверу
/api-hello-world — не будет
/apii — тоже не будет`,
    text12: `Осталось научиться раздавать фронтенд. Для этого в конфигурацию nginx нужно добавить директиву root, передав ей путь к папке со статическими файлами:`,
    code10: `root /home/praktikum/news-frontend;`,
    text13: `Добавить её можно где-то в блоке server, например, после директивы server_name:`,
    code11: `server {
  listen 80;
  server_name mestoapp.tk www.mestoapp.tk;
  root /home/praktikum/news-frontend;
  location /api/ {
    ...`,
    text14: `Всё, что остаётся сделать после этого — перезапустить nginx:`,
    code12: `sudo systemctl restart nginx`,
    subtitle3: `Бэкенд на поддомене`,
    text15: `Предыдущий способ решает задачу разделения адресов для фронтенда и бэкенда, но он не идеален.
Ведь мы уже никак не можем использовать путь /api для фронтенда, он занят.
Кроме этого, фронтенд и API должны храниться на одном сервере, мы не можем разнести их на разные машины.
Второй способ доменного разделения решает эти проблемы. В нём API хранится на отдельном поддомене, например:`,
    code13: `mestoapp.tk — фронтенд
api.mestoapp.tk — API`,
    text16: `Разберёмся, как это сделать.
Первым делом нужно создать поддомен. Сделать это можно в личном кабинете регистратора доменных имён.
Во всех уроках этой темы мы использовали Freenom, поэтому и здесь объясним на его примере.
Перейдите на сайт Freenom и войдите в систему.
После этого перейдите по ссылке в шапке сайта: Services → My Domains, чтобы отобразить домены, зарегистрированные вами.
Напротив домена, для которого хотите создать поддомен, кликните на «Manage Domain» и в открывшемся окне перейдите на вкладку`,
    subtitle4: `«Manage Freenom DNS». Здесь нужно добавить две A-записи — api и www.api:`,
    image: "image81.png",
    text17: `Это значит, что для домена mestoapp.tk мы создали поддомен api.mestoapp.tk, который указывает на тот же сервер в Яндекс Облаке.
Также домен www.api.mestoapp.tk теперь тоже ссылается на наш сервер.
Сконфигурируем nginx. Возьмём исходный файл nginx:`,
    code14: `server {
  listen 80;
  server_name mestoapp.tk www.mestoapp.tk;
  location / {
    proxy_pass http://localhost:3000;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection 'upgrade';
    proxy_set_header Host $host;
    proxy_cache_bypass $http_upgrade;
  }
  listen 443 ssl; # managed by Certbot
  ssl_certificate /etc/letsencrypt/live/mestoapp.tk/fullchain.pem; # managed by Certbot
  ssl_certificate_key /etc/letsencrypt/live/mestoapp.tk/privkey.pem; # managed by Certbot
  include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot
  ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot
}`,
    text18: `В нём нужно изменить только имя сервера, добавив api в начале:`,
    code15: {
      lang: "bash",
      value: `server {
  listen 80;
  server_name api.mestoapp.tk www.api.mestoapp.tk; # изменили имя сервера
  ...
}`,
    },
    text19: `После этого нужно полностью скопировать уже имеющуюся конфигурацию сервера и вставить в самом конце файла.
Должно получиться два одинаковых блока server:`,
    code16: {
      lang: "bash",
      value: `server {
  listen 80;
  server_name api.mestoapp.tk www.api.mestoapp.tk;
  ...
}
server {
  listen 80;
  server_name api.mestoapp.tk www.api.mestoapp.tk;
  ...
}`,
    },
    text20: `Первый блок перенаправляет запросы к API, а второй должен раздавать фронтенд.
В нём нужно изменить имя сервера обратно, так как фронтенд должен передаваться при заходе на mestoapp.tk (а не api.mestoapp.tk):`,
    code17: {
      lang: "bash",
      value: `server {
  listen 80;
  server_name mestoapp.tk www.mestoapp.tk;
  ...
}`,
    },
    text21: `Дальше нужно указать путь к папке с фронтендом:`,
    code18: `server {
  listen 80;
  server_name mestoapp.tk www.mestoapp.tk;
  root /home/praktikum/news-frontend;
  ...
}`,
    text22: `В конце второго блока server нужно удалить блок location, перенаправляющий запросы к Node.
В итоге полностью второй блок должен выглядеть так:`,
    code19: `server {
  listen 80;
  server_name diplomus.students.nomoreparties.xyz www.diplomus.students.nomoreparties.xyz
  root /home/praktikum/news-frontend;
  listen 443 ssl; # managed by Certbot
  ssl_certificate /etc/letsencrypt/live/mestoapp.tk/fullchain.pem; # managed by Certbot
  ssl_certificate_key /etc/letsencrypt/live/mestoapp.tk/privkey.pem; # managed by Certbot
  include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot
  ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot
}`,
    text23: `А весь файл конфигурации выглядит так:`,
    code20: `server {
  listen 80;
  server_name api.diplomus.students.nomoreparties.xyz www.api.diplomus.students.nomoreparties.xyz;
  location / {
    proxy_pass http://localhost:3000;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection 'upgrade';
    proxy_set_header Host $host;
    proxy_cache_bypass $http_upgrade;
  }
  listen 443 ssl; # managed by Certbot
  ssl_certificate /etc/letsencrypt/live/diplomus.students.nomoreparties.xyz/fullchain.pem; # managed by Certbot
  ssl_certificate_key /etc/letsencrypt/live/diplomus.students.nomoreparties.xyz/privkey.pem; # managed by Certbot
  include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot
  ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot
}
server {
  listen 80;
  server_name diplomus.students.nomoreparties.xyz diplomus.students.nomoreparties.xyz;
  root /home/praktikum/news-frontend;
  listen 443 ssl; # managed by Certbot
  ssl_certificate /etc/letsencrypt/live/diplomus.students.nomoreparties.xyz/fullchain.pem; # managed by Certbot
  ssl_certificate_key /etc/letsencrypt/live/diplomus.students.nomoreparties.xyz/privkey.pem; # managed by Certbot
  include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot
  ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot
}`,
    text24: `По уже сложившейся традиции перезапустите nginx:`,
    code21: `sudo systemctl restart nginx`,
    text25: `Теперь при заходе на основной домен, nginx будет отдавать фронтенд, а при обращении на поддомен api, запрос будет перенаправляться серверу Node.`,
  },
];
